{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416804b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scipy stats for parameter distributions\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Disable file validation warning\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d9e54",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Define all path variables here for easy modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15210abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using seed: 20250406\n"
     ]
    }
   ],
   "source": [
    "FILE_SUFFIX = 'bottom10pct_wealth_share'\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 20250406\n",
    "\n",
    "# Input paths\n",
    "INPUT_DIR = 'input'\n",
    "IMPUTED_DIR = f'{INPUT_DIR}/imputed'\n",
    "REFERENCE_DIR = 'reference'\n",
    "\n",
    "# Data files\n",
    "DATA_FILE = f'{IMPUTED_DIR}/df_wide_knn_imputed.csv'\n",
    "INDICATOR_LOOKUP_FILE = f'{REFERENCE_DIR}/indicator_lookup.csv'\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = 'output'\n",
    "MODELS_DIR = f'{OUTPUT_DIR}/models'\n",
    "PREDICTIONS_DIR = f'{OUTPUT_DIR}/predictions'\n",
    "FEATURE_IMPORTANCE_DIR = f'{OUTPUT_DIR}/feature_importance'\n",
    "\n",
    "# Output files\n",
    "# - Base model outputs\n",
    "MODEL_FILE = f'{MODELS_DIR}/xgb_model_{FILE_SUFFIX}.pkl'\n",
    "PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_predictions_{FILE_SUFFIX}.csv'\n",
    "FEATURE_IMPORTANCES_FILE = f'{FEATURE_IMPORTANCE_DIR}/feature_importances_{FILE_SUFFIX}.csv'\n",
    "\n",
    "# - Best model outputs\n",
    "BEST_MODEL_FILE = f'{MODELS_DIR}/xgb_best_model_{FILE_SUFFIX}.pkl'\n",
    "BEST_PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_best_predictions_{FILE_SUFFIX}.csv'\n",
    "BEST_FEATURE_IMPORTANCES_FILE = f'{FEATURE_IMPORTANCE_DIR}/feature_importances_best_{FILE_SUFFIX}.csv'\n",
    "BEST_PARAMS_FILE = f'{MODELS_DIR}/best_model_params_{FILE_SUFFIX}.json'\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURE_IMPORTANCE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded. Using seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5196303",
   "metadata": {},
   "source": [
    "# Select Data for Train/Test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bad113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 20250406\n",
      "\n",
      "input/imputed/df_wide_knn_imputed.csv loaded.\n",
      "\n",
      "Full Data Shape: 16,960 x 1,485\n",
      "Full Data Elements: 25,185,600\n",
      "Target Shape: 16,960 x 2\n",
      "\n",
      "Data Shape (drop na on wealth indc): 2,110 x 1,485\n",
      "Data Elements (drop na on wealth indc): 3,133,350\n",
      "Target Shape (drop na on wealth indc): 2,110\n",
      "\n",
      "GINI Data Shape (drop na on GINI): 2,111 x 1,485\n",
      "GINI Data Elements (drop na on GINI): 3,134,835\n",
      "GINI Target Shape (drop na on GINI): 2,111 x 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"SEED: {SEED}\")\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "print(f\"\\n{DATA_FILE} loaded.\")\n",
    "\n",
    "# Define target indicators for top and bottom 10% wealth share\n",
    "target_top = \"SI.DST.10TH.10\"    # Top 10% wealth share\n",
    "target_bottom = \"SI.DST.FRST.10\" # Bottom 10% wealth share\n",
    "target_gini = \"SI.POV.GINI\"      # Gini Index\n",
    "\n",
    "# Exclude identifier columns and target columns from features\n",
    "exclude_columns = [\"Country Name\", \"Country Code\", \"Year\", target_top, target_bottom, target_gini]\n",
    "wealth_share_columns = [col for col in data.columns if col.startswith(\"SI.DST\")]\n",
    "exclude_columns += wealth_share_columns\n",
    "feature_columns = [col for col in data.columns if col not in exclude_columns]\n",
    "\n",
    "# evaluate data completeness based on targets\n",
    "X_full = data[feature_columns].copy()\n",
    "y_full = data[[target_top, target_bottom]].copy()\n",
    "\n",
    "print(f\"\\nFull Data Shape: {X_full.shape[0]:,} x {X_full.shape[1]:,}\")\n",
    "print(f\"Full Data Elements: {X_full.size:,}\")\n",
    "print(f\"Target Shape: {y_full.shape[0]:,} x {y_full.shape[1]:,}\")\n",
    "\n",
    "X_wealth = data.dropna(subset=[target_top, target_bottom])[feature_columns].copy()\n",
    "y_wealth = data.dropna(subset=[target_top, target_bottom])[target_bottom].copy()\n",
    "\n",
    "print(f\"\\nData Shape (drop na on wealth indc): {X_wealth.shape[0]:,} x {X_wealth.shape[1]:,}\")\n",
    "print(f\"Data Elements (drop na on wealth indc): {X_wealth.size:,}\")\n",
    "print(f\"Target Shape (drop na on wealth indc): {y_wealth.shape[0]:,}\")\n",
    "\n",
    "X_gini = data.dropna(subset=[target_gini])[feature_columns].copy()\n",
    "y_gini = data.dropna(subset=[target_gini])[[target_gini]].copy()\n",
    "\n",
    "print(f\"\\nGINI Data Shape (drop na on GINI): {X_gini.shape[0]:,} x {X_gini.shape[1]:,}\")\n",
    "print(f\"GINI Data Elements (drop na on GINI): {X_gini.size:,}\")\n",
    "print(f\"GINI Target Shape (drop na on GINI): {y_gini.shape[0]:,} x {y_gini.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183e8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Shape: 2,110 x 1,485\n",
      "Data elements: 3,133,350\n"
     ]
    }
   ],
   "source": [
    "# data selection\n",
    "X = X_wealth.values\n",
    "y = y_wealth.values\n",
    "\n",
    "print(f\"\\nData Shape: {X.shape[0]:,} x {X.shape[1]:,}\")\n",
    "print(f\"Data elements: {X.size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad58538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Shape: 1,477 x 1,485\n",
      "Train elements: 2,193,345\n",
      "Train target elements: 1,477\n",
      "\n",
      "Validation Shape: 316 x 1,485\n",
      "Validation elements: 469,260\n",
      "Validation target elements: 316\n",
      "\n",
      "Test Shape: 317 x 1,485\n",
      "Test elements: 470,745\n",
      "Test target elements: 317\n",
      "\n",
      "Pct split: 70.00% train, 14.98% val, 15.02% test\n"
     ]
    }
   ],
   "source": [
    "# train test validation split\n",
    "# Simple approach: random split treating each observation independently\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=SEED\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain Shape: {X_train.shape[0]:,} x {X_train.shape[1]:,}\")\n",
    "print(f\"Train elements: {X_train.size:,}\")\n",
    "print(f\"Train target elements: {y_train.size:,}\")\n",
    "print(f\"\\nValidation Shape: {X_val.shape[0]:,} x {X_val.shape[1]:,}\")\n",
    "print(f\"Validation elements: {X_val.size:,}\")\n",
    "print(f\"Validation target elements: {y_val.size:,}\")\n",
    "print(f\"\\nTest Shape: {X_test.shape[0]:,} x {X_test.shape[1]:,}\")\n",
    "print(f\"Test elements: {X_test.size:,}\")\n",
    "print(f\"Test target elements: {y_test.size:,}\")\n",
    "print(f\"\\nPct split: {X_train.shape[0] / X.shape[0]:.2%} train, {X_val.shape[0] / X.shape[0]:.2%} val, {X_test.shape[0] / X.shape[0]:.2%} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6021b2",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1513a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train MSE: 0.0555, Train R2: 0.9391\n",
      "Validation MSE: 0.0897, Validation R2: 0.9047\n",
      "Test MSE: 0.1052, Test R2: 0.8990\n",
      "\n",
      "Model saved to output/models/xgb_model_bottom10pct_wealth_share.pkl\n",
      "\n",
      "Predictions saved to output/predictions/xgb_predictions_bottom10pct_wealth_share.csv\n",
      "\n",
      "Feature importances saved to output/feature_importance/feature_importances_bottom10pct_wealth_share.csv\n",
      "\n",
      "Top 10 feature importances:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "27f0598d-071b-43e5-9ace-f2dfae85a897",
       "rows": [
        [
         "0",
         "TM.VAL.MRCH.R3.ZS",
         "Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)",
         "0.0799701"
        ],
        [
         "1",
         "SH.DTH.INJR.ZS",
         "Cause of death, by injury (% of total)",
         "0.049651098"
        ],
        [
         "2",
         "TX.VAL.MRCH.R3.ZS",
         "Merchandise exports to low- and middle-income economies in Latin America & the Caribbean (% of total merchandise exports)",
         "0.03920393"
        ],
        [
         "3",
         "IC.FRM.CMPU.ZS",
         "Firms competing against unregistered firms (% of firms)",
         "0.036720484"
        ],
        [
         "4",
         "IC.FRM.RSDV.ZS",
         "Firms that spend on R&D (% of firms)",
         "0.036602624"
        ],
        [
         "5",
         "SI.POV.DDAY",
         "Poverty headcount ratio at $2.15 a day (2017 PPP) (% of population)",
         "0.019516388"
        ],
        [
         "6",
         "ER.GDP.FWTL.M3.KD",
         "Water productivity, total (constant 2015 US$ GDP per cubic meter of total freshwater withdrawal)",
         "0.014570868"
        ],
        [
         "7",
         "ER.H2O.FWDM.ZS",
         "Annual freshwater withdrawals, domestic (% of total freshwater withdrawal)",
         "0.014513791"
        ],
        [
         "8",
         "SH.DTH.IMRT",
         "Number of infant deaths",
         "0.013812478"
        ],
        [
         "9",
         "SH.STA.WAST.MA.ZS",
         "Prevalence of wasting, weight for height, male (% of children under 5)",
         "0.013412293"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TM.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise imports from low- and middle-incom...</td>\n",
       "      <td>0.079970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SH.DTH.INJR.ZS</td>\n",
       "      <td>Cause of death, by injury (% of total)</td>\n",
       "      <td>0.049651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TX.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise exports to low- and middle-income ...</td>\n",
       "      <td>0.039204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IC.FRM.CMPU.ZS</td>\n",
       "      <td>Firms competing against unregistered firms (% ...</td>\n",
       "      <td>0.036720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IC.FRM.RSDV.ZS</td>\n",
       "      <td>Firms that spend on R&amp;D (% of firms)</td>\n",
       "      <td>0.036603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SI.POV.DDAY</td>\n",
       "      <td>Poverty headcount ratio at $2.15 a day (2017 P...</td>\n",
       "      <td>0.019516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ER.GDP.FWTL.M3.KD</td>\n",
       "      <td>Water productivity, total (constant 2015 US$ G...</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ER.H2O.FWDM.ZS</td>\n",
       "      <td>Annual freshwater withdrawals, domestic (% of ...</td>\n",
       "      <td>0.014514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SH.DTH.IMRT</td>\n",
       "      <td>Number of infant deaths</td>\n",
       "      <td>0.013812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SH.STA.WAST.MA.ZS</td>\n",
       "      <td>Prevalence of wasting, weight for height, male...</td>\n",
       "      <td>0.013412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Indicator Code                                     Indicator Name  \\\n",
       "0  TM.VAL.MRCH.R3.ZS  Merchandise imports from low- and middle-incom...   \n",
       "1     SH.DTH.INJR.ZS             Cause of death, by injury (% of total)   \n",
       "2  TX.VAL.MRCH.R3.ZS  Merchandise exports to low- and middle-income ...   \n",
       "3     IC.FRM.CMPU.ZS  Firms competing against unregistered firms (% ...   \n",
       "4     IC.FRM.RSDV.ZS               Firms that spend on R&D (% of firms)   \n",
       "5        SI.POV.DDAY  Poverty headcount ratio at $2.15 a day (2017 P...   \n",
       "6  ER.GDP.FWTL.M3.KD  Water productivity, total (constant 2015 US$ G...   \n",
       "7     ER.H2O.FWDM.ZS  Annual freshwater withdrawals, domestic (% of ...   \n",
       "8        SH.DTH.IMRT                            Number of infant deaths   \n",
       "9  SH.STA.WAST.MA.ZS  Prevalence of wasting, weight for height, male...   \n",
       "\n",
       "   Importance  \n",
       "0    0.079970  \n",
       "1    0.049651  \n",
       "2    0.039204  \n",
       "3    0.036720  \n",
       "4    0.036603  \n",
       "5    0.019516  \n",
       "6    0.014571  \n",
       "7    0.014514  \n",
       "8    0.013812  \n",
       "9    0.013412  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = xgb.XGBRegressor(\n",
    "    # Basic parameters\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,  # Lower learning rate for better generalization\n",
    "    \n",
    "    # Tree structure regularization\n",
    "    max_depth=3,  # Lower max_depth to prevent complex trees\n",
    "    min_child_weight=5,  # Higher values prevent overfitting on rare feature combinations\n",
    "    gamma=1,  # Minimum loss reduction required for further partition\n",
    "    \n",
    "    # Sampling regularization\n",
    "    subsample=0.8,  # Train on 80% of data points each iteration\n",
    "    colsample_bytree=0.7,  # Train each tree on 70% of features\n",
    "    colsample_bylevel=0.7,  # Sample features at each level\n",
    "    \n",
    "    # L1/L2 regularization\n",
    "    reg_alpha=1.0,  # L1 regularization on weights\n",
    "    reg_lambda=1.0,  # L2 regularization on weights\n",
    "    \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "val_mse = mean_squared_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"\\nTrain MSE: {train_mse:.4f}, Train R2: {train_r2:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:.4f}, Validation R2: {val_r2:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, MODEL_FILE)\n",
    "print(f\"\\nModel saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nPredictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_df.to_csv(FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nFeature importances saved to {FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances:\")\n",
    "feature_lookup = pd.read_csv(INDICATOR_LOOKUP_FILE)\n",
    "feature_importances_df = feature_importances_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bf6d5",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a035450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "Best parameters: {'model__colsample_bylevel': 0.9760773204143818, 'model__colsample_bytree': 0.7892277714194997, 'model__gamma': 0.14046843914487694, 'model__learning_rate': 0.07814725395454945, 'model__max_depth': 3, 'model__min_child_weight': 3, 'model__n_estimators': 142, 'model__reg_alpha': 2.2350968296772424, 'model__reg_lambda': 0.6953962195156492, 'model__subsample': 0.774978624684772}\n",
      "Best cross-validation RMSE: 0.2754\n",
      "\n",
      "Train RMSE (best model): 0.1483, Train R2 (best model): 0.9758\n",
      "Validation RMSE (best model): 0.2460, Validation R2 (best model): 0.9357\n",
      "Test RMSE (best model): 0.2727, Test R2 (best model): 0.9286\n",
      "\n",
      "Best model saved to output/models/xgb_best_model_bottom10pct_wealth_share.pkl\n",
      "\n",
      "Best model predictions saved to output/predictions/xgb_best_predictions_bottom10pct_wealth_share.csv\n",
      "\n",
      "Best model feature importances saved to output/models/feature_importances_best_bottom10pct_wealth_share.csv\n",
      "\n",
      "Top 10 feature importances (best model):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ad8b1ba9-955b-4a2e-af65-67fc28de79fa",
       "rows": [
        [
         "0",
         "TM.VAL.MRCH.R3.ZS",
         "Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)",
         "0.118835315"
        ],
        [
         "1",
         "TX.VAL.MRCH.R3.ZS",
         "Merchandise exports to low- and middle-income economies in Latin America & the Caribbean (% of total merchandise exports)",
         "0.06144025"
        ],
        [
         "2",
         "SH.PRV.SMOK.MA",
         "Prevalence of current tobacco use, males (% of male adults)",
         "0.0505211"
        ],
        [
         "3",
         "SH.STA.WAST.MA.ZS",
         "Prevalence of wasting, weight for height, male (% of children under 5)",
         "0.034012362"
        ],
        [
         "4",
         "SH.STA.WAST.FE.ZS",
         "Prevalence of wasting, weight for height, female (% of children under 5)",
         "0.029176427"
        ],
        [
         "5",
         "SH.DTH.NMRT",
         "Number of neonatal deaths",
         "0.02325571"
        ],
        [
         "6",
         "IC.CRD.PRVT.ZS",
         "Private credit bureau coverage (% of adults)",
         "0.021344474"
        ],
        [
         "7",
         "ER.GDP.FWTL.M3.KD",
         "Water productivity, total (constant 2015 US$ GDP per cubic meter of total freshwater withdrawal)",
         "0.017724726"
        ],
        [
         "8",
         "CC.EST",
         "Control of Corruption: Estimate",
         "0.01646656"
        ],
        [
         "9",
         "NY.GDP.PCAP.KD",
         "GDP per capita (constant 2015 US$)",
         "0.016447807"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TM.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise imports from low- and middle-incom...</td>\n",
       "      <td>0.118835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TX.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise exports to low- and middle-income ...</td>\n",
       "      <td>0.061440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SH.PRV.SMOK.MA</td>\n",
       "      <td>Prevalence of current tobacco use, males (% of...</td>\n",
       "      <td>0.050521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SH.STA.WAST.MA.ZS</td>\n",
       "      <td>Prevalence of wasting, weight for height, male...</td>\n",
       "      <td>0.034012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SH.STA.WAST.FE.ZS</td>\n",
       "      <td>Prevalence of wasting, weight for height, fema...</td>\n",
       "      <td>0.029176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SH.DTH.NMRT</td>\n",
       "      <td>Number of neonatal deaths</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IC.CRD.PRVT.ZS</td>\n",
       "      <td>Private credit bureau coverage (% of adults)</td>\n",
       "      <td>0.021344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ER.GDP.FWTL.M3.KD</td>\n",
       "      <td>Water productivity, total (constant 2015 US$ G...</td>\n",
       "      <td>0.017725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC.EST</td>\n",
       "      <td>Control of Corruption: Estimate</td>\n",
       "      <td>0.016467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NY.GDP.PCAP.KD</td>\n",
       "      <td>GDP per capita (constant 2015 US$)</td>\n",
       "      <td>0.016448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Indicator Code                                     Indicator Name  \\\n",
       "0  TM.VAL.MRCH.R3.ZS  Merchandise imports from low- and middle-incom...   \n",
       "1  TX.VAL.MRCH.R3.ZS  Merchandise exports to low- and middle-income ...   \n",
       "2     SH.PRV.SMOK.MA  Prevalence of current tobacco use, males (% of...   \n",
       "3  SH.STA.WAST.MA.ZS  Prevalence of wasting, weight for height, male...   \n",
       "4  SH.STA.WAST.FE.ZS  Prevalence of wasting, weight for height, fema...   \n",
       "5        SH.DTH.NMRT                          Number of neonatal deaths   \n",
       "6     IC.CRD.PRVT.ZS       Private credit bureau coverage (% of adults)   \n",
       "7  ER.GDP.FWTL.M3.KD  Water productivity, total (constant 2015 US$ G...   \n",
       "8             CC.EST                    Control of Corruption: Estimate   \n",
       "9     NY.GDP.PCAP.KD                 GDP per capita (constant 2015 US$)   \n",
       "\n",
       "   Importance  \n",
       "0    0.118835  \n",
       "1    0.061440  \n",
       "2    0.050521  \n",
       "3    0.034012  \n",
       "4    0.029176  \n",
       "5    0.023256  \n",
       "6    0.021344  \n",
       "7    0.017725  \n",
       "8    0.016467  \n",
       "9    0.016448  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model parameters saved to output/models/best_model_params_bottom10pct_wealth_share.json\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': uniform(0.01, 0.1),  \n",
    "    'model__max_depth': randint(2, 6),           \n",
    "    'model__min_child_weight': randint(1, 6),    \n",
    "    'model__gamma': uniform(0, 2),               \n",
    "    'model__subsample': uniform(0.7, 0.3),       \n",
    "    'model__colsample_bytree': uniform(0.7, 0.3),\n",
    "    'model__colsample_bylevel': uniform(0.7, 0.3),\n",
    "    'model__reg_alpha': uniform(0, 3),           \n",
    "    'model__reg_lambda': uniform(0.5, 3)         \n",
    "}\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBRegressor(objective='reg:squarederror', random_state=SEED))\n",
    "])\n",
    "\n",
    "# Define the scoring function\n",
    "rmse_scorer = make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)), \n",
    "                          greater_is_better=False)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25,  # Number of parameter combinations to try\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Best cross-validation RMSE: {-best_score:.4f}\")\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_train_best = best_model.predict(X_train)\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "y_pred_test_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "train_mse_best = mean_squared_error(y_train, y_pred_train_best)\n",
    "train_r2_best = r2_score(y_train, y_pred_train_best)\n",
    "val_mse_best = mean_squared_error(y_val, y_pred_val_best)\n",
    "val_r2_best = r2_score(y_val, y_pred_val_best)\n",
    "test_mse_best = mean_squared_error(y_test, y_pred_test_best)\n",
    "test_r2_best = r2_score(y_test, y_pred_test_best)\n",
    "\n",
    "# Add RMSE calculation\n",
    "train_rmse_best = np.sqrt(train_mse_best)\n",
    "val_rmse_best = np.sqrt(val_mse_best)\n",
    "test_rmse_best = np.sqrt(test_mse_best)\n",
    "\n",
    "print(f\"\\nTrain RMSE (best model): {train_rmse_best:.4f}, Train R2 (best model): {train_r2_best:.4f}\")\n",
    "print(f\"Validation RMSE (best model): {val_rmse_best:.4f}, Validation R2 (best model): {val_r2_best:.4f}\")\n",
    "print(f\"Test RMSE (best model): {test_rmse_best:.4f}, Test R2 (best model): {test_r2_best:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, BEST_MODEL_FILE)\n",
    "print(f\"\\nBest model saved to {BEST_MODEL_FILE}\")\n",
    "\n",
    "# Save the best model predictions\n",
    "predictions_best_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test_best\n",
    "})\n",
    "predictions_best_df.to_csv(BEST_PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nBest model predictions saved to {BEST_PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the best model feature importances\n",
    "importances_best = best_model.named_steps['model'].feature_importances_\n",
    "feature_importances_best_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances_best\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_best_df.to_csv(BEST_FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nBest model feature importances saved to {BEST_FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances (best model):\")\n",
    "feature_importances_best_df = feature_importances_best_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_best_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(BEST_PARAMS_FILE, 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "print(f\"\\nBest model parameters saved to {BEST_PARAMS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
