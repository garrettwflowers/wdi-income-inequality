{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "416804b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scipy stats for parameter distributions\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Disable file validation warning\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d9e54",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Define all path variables here for easy modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15210abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using seed: 20250406\n"
     ]
    }
   ],
   "source": [
    "FILE_SUFFIX = 'GINI'\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 20250406\n",
    "\n",
    "# Input paths\n",
    "INPUT_DIR = 'input'\n",
    "IMPUTED_DIR = f'{INPUT_DIR}/imputed'\n",
    "REFERENCE_DIR = 'reference'\n",
    "\n",
    "# Data files\n",
    "DATA_FILE = f'{IMPUTED_DIR}/df_wide_knn_imputed.csv'\n",
    "INDICATOR_LOOKUP_FILE = f'{REFERENCE_DIR}/indicator_lookup.csv'\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = 'output'\n",
    "MODELS_DIR = f'{OUTPUT_DIR}/models'\n",
    "PREDICTIONS_DIR = f'{OUTPUT_DIR}/predictions'\n",
    "FEATURE_IMPORTANCE_DIR = f'{OUTPUT_DIR}/feature_importance'\n",
    "\n",
    "# Output files\n",
    "# - Base model outputs\n",
    "MODEL_FILE = f'{MODELS_DIR}/xgb_model_{FILE_SUFFIX}.pkl'\n",
    "PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_predictions_{FILE_SUFFIX}.csv'\n",
    "FEATURE_IMPORTANCES_FILE = f'{FEATURE_IMPORTANCE_DIR}/feature_importances_{FILE_SUFFIX}.csv'\n",
    "\n",
    "# - Best model outputs\n",
    "BEST_MODEL_FILE = f'{MODELS_DIR}/xgb_best_model_{FILE_SUFFIX}.pkl'\n",
    "BEST_PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_best_predictions_{FILE_SUFFIX}.csv'\n",
    "BEST_FEATURE_IMPORTANCES_FILE = f'{MODELS_DIR}/feature_importances_best_{FILE_SUFFIX}.csv'\n",
    "BEST_PARAMS_FILE = f'{MODELS_DIR}/best_model_params_{FILE_SUFFIX}.json'\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURE_IMPORTANCE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded. Using seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5196303",
   "metadata": {},
   "source": [
    "# Select Data for Train/Test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67bad113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 20250406\n",
      "\n",
      "input/imputed/df_wide_knn_imputed.csv loaded.\n",
      "\n",
      "Full Data Shape: 16,960 x 1,485\n",
      "Full Data Elements: 25,185,600\n",
      "Target Shape: 16,960 x 2\n",
      "\n",
      "Data Shape (drop na on wealth indc): 2,110 x 1,485\n",
      "Data Elements (drop na on wealth indc): 3,133,350\n",
      "Target Shape (drop na on wealth indc): 2,110 x 2\n",
      "\n",
      "GINI Data Shape (drop na on GINI): 2,111 x 1,485\n",
      "GINI Data Elements (drop na on GINI): 3,134,835\n",
      "GINI Target Shape (drop na on GINI): 2,111 x 1\n",
      "\n",
      "input/imputed/df_wide_knn_imputed.csv loaded.\n",
      "\n",
      "Full Data Shape: 16,960 x 1,485\n",
      "Full Data Elements: 25,185,600\n",
      "Target Shape: 16,960 x 2\n",
      "\n",
      "Data Shape (drop na on wealth indc): 2,110 x 1,485\n",
      "Data Elements (drop na on wealth indc): 3,133,350\n",
      "Target Shape (drop na on wealth indc): 2,110 x 2\n",
      "\n",
      "GINI Data Shape (drop na on GINI): 2,111 x 1,485\n",
      "GINI Data Elements (drop na on GINI): 3,134,835\n",
      "GINI Target Shape (drop na on GINI): 2,111 x 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"SEED: {SEED}\")\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "print(f\"\\n{DATA_FILE} loaded.\")\n",
    "\n",
    "# Define target indicators for top and bottom 10% wealth share\n",
    "target_top = \"SI.DST.10TH.10\"    # Top 10% wealth share\n",
    "target_bottom = \"SI.DST.FRST.10\" # Bottom 10% wealth share\n",
    "target_gini = \"SI.POV.GINI\"      # Gini Index\n",
    "\n",
    "# Exclude identifier columns and target columns from features\n",
    "exclude_columns = [\"Country Name\", \"Country Code\", \"Year\", target_top, target_bottom, target_gini]\n",
    "wealth_share_columns = [col for col in data.columns if col.startswith(\"SI.DST\")]\n",
    "exclude_columns += wealth_share_columns\n",
    "feature_columns = [col for col in data.columns if col not in exclude_columns]\n",
    "\n",
    "# evaluate data completeness based on targets\n",
    "X_full = data[feature_columns].copy()\n",
    "y_full = data[[target_top, target_bottom]].copy()\n",
    "\n",
    "print(f\"\\nFull Data Shape: {X_full.shape[0]:,} x {X_full.shape[1]:,}\")\n",
    "print(f\"Full Data Elements: {X_full.size:,}\")\n",
    "print(f\"Target Shape: {y_full.shape[0]:,} x {y_full.shape[1]:,}\")\n",
    "\n",
    "X_wealth = data.dropna(subset=[target_top, target_bottom])[feature_columns].copy()\n",
    "y_wealth = data.dropna(subset=[target_top, target_bottom])[[target_top, target_bottom]].copy()\n",
    "\n",
    "print(f\"\\nData Shape (drop na on wealth indc): {X_wealth.shape[0]:,} x {X_wealth.shape[1]:,}\")\n",
    "print(f\"Data Elements (drop na on wealth indc): {X_wealth.size:,}\")\n",
    "print(f\"Target Shape (drop na on wealth indc): {y_wealth.shape[0]:,} x {y_wealth.shape[1]:,}\")\n",
    "\n",
    "X_gini = data.dropna(subset=[target_gini])[feature_columns].copy()\n",
    "y_gini = data.dropna(subset=[target_gini])[[target_gini]].copy()\n",
    "\n",
    "print(f\"\\nGINI Data Shape (drop na on GINI): {X_gini.shape[0]:,} x {X_gini.shape[1]:,}\")\n",
    "print(f\"GINI Data Elements (drop na on GINI): {X_gini.size:,}\")\n",
    "print(f\"GINI Target Shape (drop na on GINI): {y_gini.shape[0]:,} x {y_gini.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "183e8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Shape: 2,111 x 1,485\n",
      "Data elements: 3,134,835\n"
     ]
    }
   ],
   "source": [
    "# data selection\n",
    "X = X_gini.values\n",
    "y = data.dropna(subset=[target_gini])[target_gini].values\n",
    "\n",
    "print(f\"\\nData Shape: {X.shape[0]:,} x {X.shape[1]:,}\")\n",
    "print(f\"Data elements: {X.size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ad58538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Shape: 1,477 x 1,485\n",
      "Train elements: 2,193,345\n",
      "Train target elements: 1,477\n",
      "\n",
      "Validation Shape: 317 x 1,485\n",
      "Validation elements: 470,745\n",
      "Validation target elements: 317\n",
      "\n",
      "Test Shape: 317 x 1,485\n",
      "Test elements: 470,745\n",
      "Test target elements: 317\n",
      "\n",
      "Pct split: 69.97% train, 15.02% val, 15.02% test\n"
     ]
    }
   ],
   "source": [
    "# train test validation split\n",
    "# Simple approach: random split treating each observation independently\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=SEED\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain Shape: {X_train.shape[0]:,} x {X_train.shape[1]:,}\")\n",
    "print(f\"Train elements: {X_train.size:,}\")\n",
    "print(f\"Train target elements: {y_train.size:,}\")\n",
    "print(f\"\\nValidation Shape: {X_val.shape[0]:,} x {X_val.shape[1]:,}\")\n",
    "print(f\"Validation elements: {X_val.size:,}\")\n",
    "print(f\"Validation target elements: {y_val.size:,}\")\n",
    "print(f\"\\nTest Shape: {X_test.shape[0]:,} x {X_test.shape[1]:,}\")\n",
    "print(f\"Test elements: {X_test.size:,}\")\n",
    "print(f\"Test target elements: {y_test.size:,}\")\n",
    "print(f\"\\nPct split: {X_train.shape[0] / X.shape[0]:.2%} train, {X_val.shape[0] / X.shape[0]:.2%} val, {X_test.shape[0] / X.shape[0]:.2%} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6021b2",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1513a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train MSE: 4.1112, Train R2: 0.9471\n",
      "Validation MSE: 6.7381, Validation R2: 0.9087\n",
      "Test MSE: 9.5082, Test R2: 0.8839\n",
      "\n",
      "Model saved to output/models/xgb_model_GINI.pkl\n",
      "\n",
      "Predictions saved to output/predictions/xgb_predictions_GINI.csv\n",
      "\n",
      "Feature importances saved to output/feature_importance/feature_importances_GINI.csv\n",
      "\n",
      "Top 10 feature importances:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "65a67f35-8ade-4744-b340-13ed31c2a019",
       "rows": [
        [
         "0",
         "SP.ADO.TFRT",
         "Adolescent fertility rate (births per 1,000 women ages 15-19)",
         "0.081524715"
        ],
        [
         "1",
         "SH.STA.ODFC.ZS",
         "People practicing open defecation (% of population)",
         "0.064791985"
        ],
        [
         "2",
         "per_si_allsi.cov_q1_tot",
         "Coverage of social insurance programs in poorest quintile (% of population)",
         "0.061333604"
        ],
        [
         "3",
         "TM.TAX.MANF.BR.ZS",
         "Bound rate, simple mean, manufactured products (%)",
         "0.060353097"
        ],
        [
         "4",
         "TM.VAL.MRCH.R3.ZS",
         "Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)",
         "0.025910687"
        ],
        [
         "5",
         "SH.STA.WAST.FE.ZS",
         "Prevalence of wasting, weight for height, female (% of children under 5)",
         "0.021397026"
        ],
        [
         "6",
         "TX.VAL.MRCH.R3.ZS",
         "Merchandise exports to low- and middle-income economies in Latin America & the Caribbean (% of total merchandise exports)",
         "0.020062106"
        ],
        [
         "7",
         "SI.POV.SOPO",
         "Poverty headcount ratio at societal poverty line (% of population)",
         "0.019725379"
        ],
        [
         "8",
         "SH.HIV.INCD.YG.P3",
         "Incidence of HIV, ages 15-24 (per 1,000 uninfected population ages 15-24)",
         "0.01924952"
        ],
        [
         "9",
         "per_si_allsi.ben_q1_tot",
         "Benefit incidence of social insurance programs to poorest quintile (% of total social insurance benefits)",
         "0.015951658"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>0.081525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SH.STA.ODFC.ZS</td>\n",
       "      <td>People practicing open defecation (% of popula...</td>\n",
       "      <td>0.064792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>per_si_allsi.cov_q1_tot</td>\n",
       "      <td>Coverage of social insurance programs in poore...</td>\n",
       "      <td>0.061334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TM.TAX.MANF.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, manufactured products...</td>\n",
       "      <td>0.060353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TM.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise imports from low- and middle-incom...</td>\n",
       "      <td>0.025911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SH.STA.WAST.FE.ZS</td>\n",
       "      <td>Prevalence of wasting, weight for height, fema...</td>\n",
       "      <td>0.021397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TX.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise exports to low- and middle-income ...</td>\n",
       "      <td>0.020062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SI.POV.SOPO</td>\n",
       "      <td>Poverty headcount ratio at societal poverty li...</td>\n",
       "      <td>0.019725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SH.HIV.INCD.YG.P3</td>\n",
       "      <td>Incidence of HIV, ages 15-24 (per 1,000 uninfe...</td>\n",
       "      <td>0.019250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>per_si_allsi.ben_q1_tot</td>\n",
       "      <td>Benefit incidence of social insurance programs...</td>\n",
       "      <td>0.015952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indicator Code                                     Indicator Name  \\\n",
       "0              SP.ADO.TFRT  Adolescent fertility rate (births per 1,000 wo...   \n",
       "1           SH.STA.ODFC.ZS  People practicing open defecation (% of popula...   \n",
       "2  per_si_allsi.cov_q1_tot  Coverage of social insurance programs in poore...   \n",
       "3        TM.TAX.MANF.BR.ZS  Bound rate, simple mean, manufactured products...   \n",
       "4        TM.VAL.MRCH.R3.ZS  Merchandise imports from low- and middle-incom...   \n",
       "5        SH.STA.WAST.FE.ZS  Prevalence of wasting, weight for height, fema...   \n",
       "6        TX.VAL.MRCH.R3.ZS  Merchandise exports to low- and middle-income ...   \n",
       "7              SI.POV.SOPO  Poverty headcount ratio at societal poverty li...   \n",
       "8        SH.HIV.INCD.YG.P3  Incidence of HIV, ages 15-24 (per 1,000 uninfe...   \n",
       "9  per_si_allsi.ben_q1_tot  Benefit incidence of social insurance programs...   \n",
       "\n",
       "   Importance  \n",
       "0    0.081525  \n",
       "1    0.064792  \n",
       "2    0.061334  \n",
       "3    0.060353  \n",
       "4    0.025911  \n",
       "5    0.021397  \n",
       "6    0.020062  \n",
       "7    0.019725  \n",
       "8    0.019250  \n",
       "9    0.015952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = xgb.XGBRegressor(\n",
    "    # Basic parameters\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,  # Lower learning rate for better generalization\n",
    "    \n",
    "    # Tree structure regularization\n",
    "    max_depth=3,  # Lower max_depth to prevent complex trees\n",
    "    min_child_weight=5,  # Higher values prevent overfitting on rare feature combinations\n",
    "    gamma=1,  # Minimum loss reduction required for further partition\n",
    "    \n",
    "    # Sampling regularization\n",
    "    subsample=0.8,  # Train on 80% of data points each iteration\n",
    "    colsample_bytree=0.7,  # Train each tree on 70% of features\n",
    "    colsample_bylevel=0.7,  # Sample features at each level\n",
    "    \n",
    "    # L1/L2 regularization\n",
    "    reg_alpha=1.0,  # L1 regularization on weights\n",
    "    reg_lambda=1.0,  # L2 regularization on weights\n",
    "    \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "val_mse = mean_squared_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"\\nTrain MSE: {train_mse:.4f}, Train R2: {train_r2:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:.4f}, Validation R2: {val_r2:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, MODEL_FILE)\n",
    "print(f\"\\nModel saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nPredictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_df.to_csv(FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nFeature importances saved to {FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances:\")\n",
    "feature_lookup = pd.read_csv(INDICATOR_LOOKUP_FILE)\n",
    "feature_importances_df = feature_importances_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bf6d5",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a035450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "Best parameters: {'model__colsample_bylevel': 0.9010517491308082, 'model__colsample_bytree': 0.9395992960433877, 'model__gamma': 0.6331108417581415, 'model__learning_rate': 0.08723901599377133, 'model__max_depth': 5, 'model__min_child_weight': 5, 'model__n_estimators': 133, 'model__reg_alpha': 1.8688165721823782, 'model__reg_lambda': 1.464786088638586, 'model__subsample': 0.9228761938728909}\n",
      "Best cross-validation RMSE: 2.4505\n",
      "\n",
      "Train RMSE (best model): 0.3733, Train R2 (best model): 0.9982\n",
      "Validation RMSE (best model): 2.2403, Validation R2 (best model): 0.9320\n",
      "Test RMSE (best model): 2.6148, Test R2 (best model): 0.9165\n",
      "\n",
      "Best model saved to output/models/xgb_best_model_GINI.pkl\n",
      "\n",
      "Best model predictions saved to output/predictions/xgb_best_predictions_GINI.csv\n",
      "\n",
      "Best model feature importances saved to output/models/feature_importances_best_GINI.csv\n",
      "\n",
      "Top 10 feature importances (best model):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb1339c6-42b0-4e5f-953d-42ca2d6e787f",
       "rows": [
        [
         "0",
         "SP.ADO.TFRT",
         "Adolescent fertility rate (births per 1,000 women ages 15-19)",
         "0.12379675"
        ],
        [
         "1",
         "TM.TAX.MANF.BR.ZS",
         "Bound rate, simple mean, manufactured products (%)",
         "0.053721465"
        ],
        [
         "2",
         "TM.VAL.MRCH.R3.ZS",
         "Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)",
         "0.05278881"
        ],
        [
         "3",
         "VC.IHR.PSRC.P5",
         "Intentional homicides (per 100,000 people)",
         "0.04130497"
        ],
        [
         "4",
         "SI.POV.SOPO",
         "Poverty headcount ratio at societal poverty line (% of population)",
         "0.035400353"
        ],
        [
         "5",
         "SH.HIV.1524.FE.ZS",
         "Prevalence of HIV, female (% ages 15-24)",
         "0.024370434"
        ],
        [
         "6",
         "TX.VAL.MRCH.R3.ZS",
         "Merchandise exports to low- and middle-income economies in Latin America & the Caribbean (% of total merchandise exports)",
         "0.018533038"
        ],
        [
         "7",
         "TX.VAL.MRCH.R2.ZS",
         "Merchandise exports to low- and middle-income economies in Europe & Central Asia (% of total merchandise exports)",
         "0.017512165"
        ],
        [
         "8",
         "SE.PRM.DURS",
         "Primary education, duration (years)",
         "0.017194532"
        ],
        [
         "9",
         "SH.HIV.INCD.ZS",
         "Incidence of HIV, ages 15-49 (per 1,000 uninfected population ages 15-49)",
         "0.016831331"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>0.123797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TM.TAX.MANF.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, manufactured products...</td>\n",
       "      <td>0.053721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TM.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise imports from low- and middle-incom...</td>\n",
       "      <td>0.052789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VC.IHR.PSRC.P5</td>\n",
       "      <td>Intentional homicides (per 100,000 people)</td>\n",
       "      <td>0.041305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SI.POV.SOPO</td>\n",
       "      <td>Poverty headcount ratio at societal poverty li...</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SH.HIV.1524.FE.ZS</td>\n",
       "      <td>Prevalence of HIV, female (% ages 15-24)</td>\n",
       "      <td>0.024370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TX.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise exports to low- and middle-income ...</td>\n",
       "      <td>0.018533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TX.VAL.MRCH.R2.ZS</td>\n",
       "      <td>Merchandise exports to low- and middle-income ...</td>\n",
       "      <td>0.017512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SE.PRM.DURS</td>\n",
       "      <td>Primary education, duration (years)</td>\n",
       "      <td>0.017195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SH.HIV.INCD.ZS</td>\n",
       "      <td>Incidence of HIV, ages 15-49 (per 1,000 uninfe...</td>\n",
       "      <td>0.016831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Indicator Code                                     Indicator Name  \\\n",
       "0        SP.ADO.TFRT  Adolescent fertility rate (births per 1,000 wo...   \n",
       "1  TM.TAX.MANF.BR.ZS  Bound rate, simple mean, manufactured products...   \n",
       "2  TM.VAL.MRCH.R3.ZS  Merchandise imports from low- and middle-incom...   \n",
       "3     VC.IHR.PSRC.P5         Intentional homicides (per 100,000 people)   \n",
       "4        SI.POV.SOPO  Poverty headcount ratio at societal poverty li...   \n",
       "5  SH.HIV.1524.FE.ZS           Prevalence of HIV, female (% ages 15-24)   \n",
       "6  TX.VAL.MRCH.R3.ZS  Merchandise exports to low- and middle-income ...   \n",
       "7  TX.VAL.MRCH.R2.ZS  Merchandise exports to low- and middle-income ...   \n",
       "8        SE.PRM.DURS                Primary education, duration (years)   \n",
       "9     SH.HIV.INCD.ZS  Incidence of HIV, ages 15-49 (per 1,000 uninfe...   \n",
       "\n",
       "   Importance  \n",
       "0    0.123797  \n",
       "1    0.053721  \n",
       "2    0.052789  \n",
       "3    0.041305  \n",
       "4    0.035400  \n",
       "5    0.024370  \n",
       "6    0.018533  \n",
       "7    0.017512  \n",
       "8    0.017195  \n",
       "9    0.016831  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model parameters saved to output/models/best_model_params_GINI.json\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': uniform(0.01, 0.1),  \n",
    "    'model__max_depth': randint(2, 6),           \n",
    "    'model__min_child_weight': randint(1, 6),    \n",
    "    'model__gamma': uniform(0, 2),               \n",
    "    'model__subsample': uniform(0.7, 0.3),       \n",
    "    'model__colsample_bytree': uniform(0.7, 0.3),\n",
    "    'model__colsample_bylevel': uniform(0.7, 0.3),\n",
    "    'model__reg_alpha': uniform(0, 3),           \n",
    "    'model__reg_lambda': uniform(0.5, 3)         \n",
    "}\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBRegressor(objective='reg:squarederror', random_state=SEED))\n",
    "])\n",
    "\n",
    "# Define the scoring function\n",
    "rmse_scorer = make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)), \n",
    "                          greater_is_better=False)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25,  # Number of parameter combinations to try\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Best cross-validation RMSE: {-best_score:.4f}\")\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_train_best = best_model.predict(X_train)\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "y_pred_test_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "train_mse_best = mean_squared_error(y_train, y_pred_train_best)\n",
    "train_r2_best = r2_score(y_train, y_pred_train_best)\n",
    "val_mse_best = mean_squared_error(y_val, y_pred_val_best)\n",
    "val_r2_best = r2_score(y_val, y_pred_val_best)\n",
    "test_mse_best = mean_squared_error(y_test, y_pred_test_best)\n",
    "test_r2_best = r2_score(y_test, y_pred_test_best)\n",
    "\n",
    "# Add RMSE calculation\n",
    "train_rmse_best = np.sqrt(train_mse_best)\n",
    "val_rmse_best = np.sqrt(val_mse_best)\n",
    "test_rmse_best = np.sqrt(test_mse_best)\n",
    "\n",
    "print(f\"\\nTrain RMSE (best model): {train_rmse_best:.4f}, Train R2 (best model): {train_r2_best:.4f}\")\n",
    "print(f\"Validation RMSE (best model): {val_rmse_best:.4f}, Validation R2 (best model): {val_r2_best:.4f}\")\n",
    "print(f\"Test RMSE (best model): {test_rmse_best:.4f}, Test R2 (best model): {test_r2_best:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, BEST_MODEL_FILE)\n",
    "print(f\"\\nBest model saved to {BEST_MODEL_FILE}\")\n",
    "\n",
    "# Save the best model predictions\n",
    "predictions_best_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test_best\n",
    "})\n",
    "predictions_best_df.to_csv(BEST_PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nBest model predictions saved to {BEST_PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the best model feature importances\n",
    "importances_best = best_model.named_steps['model'].feature_importances_\n",
    "feature_importances_best_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances_best\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_best_df.to_csv(BEST_FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nBest model feature importances saved to {BEST_FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances (best model):\")\n",
    "feature_importances_best_df = feature_importances_best_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_best_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(BEST_PARAMS_FILE, 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "print(f\"\\nBest model parameters saved to {BEST_PARAMS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
