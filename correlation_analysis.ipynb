{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e998a5c2",
   "metadata": {},
   "source": [
    "#  Merge indicator time-series data with Categorization data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72023e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original column names: ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']\n",
      "New column names: ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'year_1960', 'year_1961', 'year_1962', 'year_1963', 'year_1964', 'year_1965', 'year_1966', 'year_1967', 'year_1968', 'year_1969', 'year_1970', 'year_1971', 'year_1972', 'year_1973', 'year_1974', 'year_1975', 'year_1976', 'year_1977', 'year_1978', 'year_1979', 'year_1980', 'year_1981', 'year_1982', 'year_1983', 'year_1984', 'year_1985', 'year_1986', 'year_1987', 'year_1988', 'year_1989', 'year_1990', 'year_1991', 'year_1992', 'year_1993', 'year_1994', 'year_1995', 'year_1996', 'year_1997', 'year_1998', 'year_1999', 'year_2000', 'year_2001', 'year_2002', 'year_2003', 'year_2004', 'year_2005', 'year_2006', 'year_2007', 'year_2008', 'year_2009', 'year_2010', 'year_2011', 'year_2012', 'year_2013', 'year_2014', 'year_2015', 'year_2016', 'year_2017', 'year_2018', 'year_2019', 'year_2020', 'year_2021', 'year_2022', 'year_2023']\n",
      "Original column names: ['Indicator Code', 'Indicator Name', 'Topic', 'Coarse_Topic']\n",
      "Modified df1 column names: ['Indicator Code', 'Indicator Name', 'Topic', 'Coarse_Topic']\n",
      "Merged dataframe columns: ['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code', 'year_1960', 'year_1961', 'year_1962', 'year_1963', 'year_1964', 'year_1965', 'year_1966', 'year_1967', 'year_1968', 'year_1969', 'year_1970', 'year_1971', 'year_1972', 'year_1973', 'year_1974', 'year_1975', 'year_1976', 'year_1977', 'year_1978', 'year_1979', 'year_1980', 'year_1981', 'year_1982', 'year_1983', 'year_1984', 'year_1985', 'year_1986', 'year_1987', 'year_1988', 'year_1989', 'year_1990', 'year_1991', 'year_1992', 'year_1993', 'year_1994', 'year_1995', 'year_1996', 'year_1997', 'year_1998', 'year_1999', 'year_2000', 'year_2001', 'year_2002', 'year_2003', 'year_2004', 'year_2005', 'year_2006', 'year_2007', 'year_2008', 'year_2009', 'year_2010', 'year_2011', 'year_2012', 'year_2013', 'year_2014', 'year_2015', 'year_2016', 'year_2017', 'year_2018', 'year_2019', 'year_2020', 'year_2021', 'year_2022', 'year_2023', 'Topic', 'Coarse_Topic']\n",
      "\n",
      "First 5 rows of merged dataframe:\n",
      "                  Country Name Country Code  \\\n",
      "0  Africa Eastern and Southern          AFE   \n",
      "1  Africa Eastern and Southern          AFE   \n",
      "2  Africa Eastern and Southern          AFE   \n",
      "3  Africa Eastern and Southern          AFE   \n",
      "4  Africa Eastern and Southern          AFE   \n",
      "\n",
      "                                      Indicator Name     Indicator Code  \\\n",
      "0  Access to clean fuels and technologies for coo...     EG.CFT.ACCS.ZS   \n",
      "1  Access to clean fuels and technologies for coo...  EG.CFT.ACCS.RU.ZS   \n",
      "2  Access to clean fuels and technologies for coo...  EG.CFT.ACCS.UR.ZS   \n",
      "3            Access to electricity (% of population)     EG.ELC.ACCS.ZS   \n",
      "4  Access to electricity, rural (% of rural popul...  EG.ELC.ACCS.RU.ZS   \n",
      "\n",
      "   year_1960  year_1961  year_1962  year_1963  year_1964  year_1965  ...  \\\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
      "1        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
      "2        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
      "3        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
      "4        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
      "\n",
      "   year_2016  year_2017  year_2018  year_2019  year_2020  year_2021  \\\n",
      "0  18.558234  19.043572  19.586457  20.192064  20.828814  21.372164   \n",
      "1   7.406706   7.666648   8.020952   8.403358   8.718306   9.097176   \n",
      "2  38.779953  39.068462  39.445526  39.818645  40.276374  40.687817   \n",
      "3  38.859598  40.223744  43.035073  44.390861  46.282371  48.127211   \n",
      "4  24.627753  25.432092  27.061929  29.154282  31.022083  32.809138   \n",
      "\n",
      "   year_2022  year_2023                                 Topic  \\\n",
      "0  22.100884        NaN  Environment: Energy production & use   \n",
      "1   9.473374        NaN  Environment: Energy production & use   \n",
      "2  41.211606        NaN  Environment: Energy production & use   \n",
      "3  48.742043        NaN  Environment: Energy production & use   \n",
      "4  33.760782        NaN  Environment: Energy production & use   \n",
      "\n",
      "            Coarse_Topic  \n",
      "0  Environment & Climate  \n",
      "1  Environment & Climate  \n",
      "2  Environment & Climate  \n",
      "3  Environment & Climate  \n",
      "4  Environment & Climate  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load the WDI CSV data\n",
    "df1 = pd.read_csv('input/raw/WDICSV.csv')\n",
    "print(\"Original column names:\", df1.columns.tolist())\n",
    "\n",
    "# Rename year columns to year_XXXX format\n",
    "year_cols = [str(year) for year in range(1960, 2024)]\n",
    "rename_dict = {col: f'year_{col}' for col in year_cols if col in df1.columns}\n",
    "df1 = df1.rename(columns=rename_dict)\n",
    "print(\"New column names:\", df1.columns.tolist())\n",
    "\n",
    "#Load Categorization data \n",
    "df2 = pd.read_csv('output/reference/indicator_lookup.csv')\n",
    "print(\"Original column names:\", df2.columns.tolist())\n",
    "\n",
    "# Rename 'Series Code' to 'Indicator Code'\n",
    "df2 = df2.rename(columns={'Series Code': 'Indicator Code'})\n",
    "print(\"Modified df1 column names:\", df2.columns.tolist())\n",
    "\n",
    "# Merge df and df1 on 'Indicator Code'\n",
    "merged_df = pd.merge(df1, df2[['Indicator Code', 'Topic', 'Coarse_Topic']], on='Indicator Code', how='left')\n",
    "print(\"Merged dataframe columns:\", merged_df.columns.tolist())\n",
    "\n",
    "# Check the first few rows of the merged dataframe\n",
    "print(\"\\nFirst 5 rows of merged dataframe:\")\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111241c",
   "metadata": {},
   "source": [
    "# Excluding all poverty/wealth indicators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d18645b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_df[merged_df['Coarse_Topic'] != \"Poverty & Inequality\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "214e08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 year columns\n",
      "Found 9 unique coarse topics\n",
      "\n",
      "Processing topic: Environment & Climate\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Environment_&_Climate_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Environment_&_Climate_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Other\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Other_correlation_table.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-d4da7b151aac>:196: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations. \n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Other_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Social Development\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Social_Development_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Social_Development_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Education\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Education_correlation_table.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-d4da7b151aac>:196: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations. \n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Education_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Economy & Finance\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Economy_&_Finance_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Economy_&_Finance_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Health\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Health_correlation_table.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-d4da7b151aac>:196: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations. \n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Health_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Infrastructure & Technology\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Infrastructure_&_Technology_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Infrastructure_&_Technology_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Government & Governance\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Government_&_Governance_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Government_&_Governance_correlation_heatmap.png\n",
      "\n",
      "Processing topic: Market\n",
      "Saved correlation table to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Market_correlation_table.csv\n",
      "Saved correlation heatmap to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/Market_correlation_heatmap.png\n",
      "Saved correlation summary to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/correlation_summary.csv\n",
      "Saved detailed report to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/indicator_correlation_report.txt\n",
      "Saved indicator removal summary visualization to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/indicator_removal_summary.png\n",
      "Creating filtered dataset with only retained indicators...\n",
      "Saved filtered dataset to /Users/varnithakurli/Library/CloudStorage/OneDrive-UCB-O365/AI Project-Varni and Garrett/1_data/1_final/filtered_dataset_without_correlated_indicators.csv\n",
      "\n",
      "Analysis complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = Path('input/correlation_analysis')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)                \n",
    "                 \n",
    "                 \n",
    "# Get year columns\n",
    "year_cols = [col for col in df.columns if col.startswith('year_')]\n",
    "print(f\"Found {len(year_cols)} year columns\")\n",
    "\n",
    "# Get unique coarse topics\n",
    "coarse_topics = df['Coarse_Topic'].dropna().unique()\n",
    "print(f\"Found {len(coarse_topics)} unique coarse topics\")\n",
    "\n",
    "# Dictionary to store removed indicators by topic\n",
    "removed_indicators = {}\n",
    "# Dictionary to store retained indicators by topic\n",
    "retained_indicators = {}\n",
    "\n",
    "# Correlation threshold for \"highly correlated\" indicators\n",
    "CORR_THRESHOLD = 0.7\n",
    "\n",
    "# Create a summary table for correlation\n",
    "correlation_summary = []\n",
    "\n",
    "# Process each coarse topic\n",
    "for topic in coarse_topics:\n",
    "    print(f\"\\nProcessing topic: {topic}\")\n",
    "    \n",
    "    # Filter data for this coarse topic\n",
    "    topic_df = df[df['Coarse_Topic'] == topic].copy()\n",
    "    \n",
    "    # Get unique indicators for this topic\n",
    "    indicators = topic_df['Indicator Name'].unique()\n",
    "    \n",
    "    if len(indicators) < 2:\n",
    "        print(f\"Topic {topic} has fewer than 2 indicators, skipping\")\n",
    "        correlation_summary.append({\n",
    "            'Coarse_Topic': topic,\n",
    "            'Original_Indicator_Count': len(indicators),\n",
    "            'Highly_Correlated_Pairs': 0,\n",
    "            'Indicators_Removed': 0,\n",
    "            'Indicators_Retained': len(indicators)\n",
    "        })\n",
    "        removed_indicators[topic] = []\n",
    "        retained_indicators[topic] = list(indicators)\n",
    "        continue\n",
    "    \n",
    "    # Create correlation data\n",
    "    corr_data = pd.DataFrame()\n",
    "    indicator_to_code = {}\n",
    "    \n",
    "    for indicator in indicators:\n",
    "        indicator_df = topic_df[topic_df['Indicator Name'] == indicator]\n",
    "        indicator_to_code[indicator] = indicator_df['Indicator Code'].iloc[0]\n",
    "        \n",
    "        # Melt to convert from wide to long format\n",
    "        melted = pd.melt(\n",
    "            indicator_df,\n",
    "            id_vars=['Country Code'], \n",
    "            value_vars=year_cols,\n",
    "            var_name='Year', \n",
    "            value_name=indicator\n",
    "        )\n",
    "        \n",
    "        melted['Year'] = melted['Year'].str.replace('year_', '')\n",
    "        \n",
    "        # Add to correlation data\n",
    "        if corr_data.empty:\n",
    "            corr_data = melted[['Country Code', 'Year', indicator]]\n",
    "        else:\n",
    "            corr_data = pd.merge(\n",
    "                corr_data, \n",
    "                melted[['Country Code', 'Year', indicator]], \n",
    "                on=['Country Code', 'Year'], \n",
    "                how='outer'\n",
    "            )\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = corr_data.drop(['Country Code', 'Year'], axis=1).corr()\n",
    "    \n",
    "    # Remove NaN columns/rows\n",
    "    correlation = correlation.dropna(how='all').dropna(how='all', axis=1)\n",
    "    \n",
    "    if correlation.shape[0] < 2:\n",
    "        print(f\"Insufficient data for correlation analysis after removing NaNs for topic {topic}\")\n",
    "        correlation_summary.append({\n",
    "            'Coarse_Topic': topic,\n",
    "            'Original_Indicator_Count': len(indicators),\n",
    "            'Highly_Correlated_Pairs': 0,\n",
    "            'Indicators_Removed': 0,\n",
    "            'Indicators_Retained': len(indicators)\n",
    "        })\n",
    "        removed_indicators[topic] = []\n",
    "        retained_indicators[topic] = list(indicators)\n",
    "        continue\n",
    "    \n",
    "    # Create a list of indicator pairs with their correlation values\n",
    "    corr_pairs = []\n",
    "    for i in range(len(correlation.columns)):\n",
    "        for j in range(i+1, len(correlation.columns)):\n",
    "            ind1 = correlation.columns[i]\n",
    "            ind2 = correlation.columns[j]\n",
    "            corr_val = correlation.iloc[i, j]\n",
    "            \n",
    "            if pd.notna(corr_val):\n",
    "                abs_corr = abs(corr_val)\n",
    "                corr_pairs.append((ind1, ind2, abs_corr))\n",
    "    \n",
    "    # Sort pairs by correlation value (descending)\n",
    "    corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    # Identify highly correlated pairs\n",
    "    high_corr_pairs = [pair for pair in corr_pairs if pair[2] >= CORR_THRESHOLD]\n",
    "    \n",
    "    # Create a table of all correlation pairs\n",
    "    corr_table = pd.DataFrame(corr_pairs, columns=['Indicator1', 'Indicator2', 'Absolute_Correlation'])\n",
    "    corr_table['Indicator1_Code'] = corr_table['Indicator1'].map(indicator_to_code)\n",
    "    corr_table['Indicator2_Code'] = corr_table['Indicator2'].map(indicator_to_code)\n",
    "    corr_table['Is_Highly_Correlated'] = corr_table['Absolute_Correlation'] >= CORR_THRESHOLD\n",
    "    \n",
    "    # Save correlation table for this topic\n",
    "    corr_table_file = output_dir / f\"{topic.replace(' ', '_')}_correlation_table.csv\"\n",
    "    corr_table.to_csv(corr_table_file, index=False)\n",
    "    print(f\"Saved correlation table to {corr_table_file}\")\n",
    "    \n",
    "    # Algorithm to remove highly correlated indicators\n",
    "    # We'll use a greedy approach: remove indicators that appear most frequently in high correlation pairs\n",
    "    to_remove = set()\n",
    "    indicator_frequency = {}\n",
    "    \n",
    "    # Count how many times each indicator appears in high correlation pairs\n",
    "    for ind1, ind2, corr_val in high_corr_pairs:\n",
    "        indicator_frequency[ind1] = indicator_frequency.get(ind1, 0) + 1\n",
    "        indicator_frequency[ind2] = indicator_frequency.get(ind2, 0) + 1\n",
    "    \n",
    "    # Sort indicators by frequency in high correlation pairs\n",
    "    sorted_indicators = sorted(indicator_frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Iteratively remove indicators until no high correlations remain\n",
    "    for ind, freq in sorted_indicators:\n",
    "        # Skip if this indicator is already marked for removal\n",
    "        if ind in to_remove:\n",
    "            continue\n",
    "        \n",
    "        # Check if there are still high correlations with this indicator\n",
    "        remaining_high_corr = False\n",
    "        for pair in high_corr_pairs:\n",
    "            ind1, ind2, corr_val = pair\n",
    "            if (ind1 == ind and ind2 not in to_remove) or (ind2 == ind and ind1 not in to_remove):\n",
    "                remaining_high_corr = True\n",
    "                break\n",
    "        \n",
    "        # If no remaining high correlations, we don't need to remove this indicator\n",
    "        if not remaining_high_corr:\n",
    "            continue\n",
    "        \n",
    "        # Otherwise, mark this indicator for removal\n",
    "        to_remove.add(ind)\n",
    "        \n",
    "        # Check if we've eliminated all high correlations\n",
    "        all_handled = True\n",
    "        for pair in high_corr_pairs:\n",
    "            ind1, ind2, corr_val = pair\n",
    "            if ind1 not in to_remove and ind2 not in to_remove:\n",
    "                all_handled = False\n",
    "                break\n",
    "        \n",
    "        if all_handled:\n",
    "            break\n",
    "    \n",
    "    # Store the results\n",
    "    removed_indicators[topic] = list(to_remove)\n",
    "    retained_indicators[topic] = [ind for ind in correlation.columns if ind not in to_remove]\n",
    "    \n",
    "    # Add to summary\n",
    "    correlation_summary.append({\n",
    "        'Coarse_Topic': topic,\n",
    "        'Original_Indicator_Count': len(correlation.columns),\n",
    "        'Highly_Correlated_Pairs': len(high_corr_pairs),\n",
    "        'Indicators_Removed': len(to_remove),\n",
    "        'Indicators_Retained': len(correlation.columns) - len(to_remove)\n",
    "    })\n",
    "    \n",
    "    # Create visualization of correlation matrix with labeled indicators to remove\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "    sns.heatmap(correlation, mask=mask, cmap=\"coolwarm\", vmin=-1, vmax=1, \n",
    "                annot=True, fmt=\".2f\", annot_kws={\"size\": 8})\n",
    "    \n",
    "    # Mark indicators to be removed\n",
    "    for i, ind in enumerate(correlation.columns):\n",
    "        if ind in to_remove:\n",
    "            plt.text(i + 0.5, i, \"X\", fontsize=12, color=\"black\", \n",
    "                    ha=\"center\", va=\"center\")\n",
    "    \n",
    "    plt.title(f\"Correlation Matrix for {topic}\\nX = Indicators to be removed\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save correlation heatmap\n",
    "    vis_file = output_dir / f\"{topic.replace(' ', '_')}_correlation_heatmap.png\"\n",
    "    plt.savefig(vis_file, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved correlation heatmap to {vis_file}\")\n",
    "\n",
    "# Create summary table\n",
    "summary_df = pd.DataFrame(correlation_summary)\n",
    "summary_file = output_dir / \"correlation_summary.csv\"\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "print(f\"Saved correlation summary to {summary_file}\")\n",
    "\n",
    "# Create detailed report\n",
    "report_file = output_dir / \"indicator_correlation_report.txt\"\n",
    "with open(report_file, 'w') as f:\n",
    "    f.write(\"INDICATOR CORRELATION ANALYSIS\\n\")\n",
    "    f.write(\"=============================\\n\\n\")\n",
    "    \n",
    "    f.write(\"SUMMARY\\n\")\n",
    "    f.write(\"-------\\n\")\n",
    "    f.write(f\"Total topics analyzed: {len(coarse_topics)}\\n\")\n",
    "    f.write(f\"Correlation threshold for removal: {CORR_THRESHOLD}\\n\\n\")\n",
    "    \n",
    "    for row in summary_df.sort_values('Highly_Correlated_Pairs', ascending=False).itertuples():\n",
    "        f.write(f\"Topic: {row.Coarse_Topic}\\n\")\n",
    "        f.write(f\"  Original indicators: {row.Original_Indicator_Count}\\n\")\n",
    "        f.write(f\"  Highly correlated pairs: {row.Highly_Correlated_Pairs}\\n\")\n",
    "        f.write(f\"  Indicators removed: {row.Indicators_Removed}\\n\")\n",
    "        f.write(f\"  Indicators retained: {row.Indicators_Retained}\\n\\n\")\n",
    "    \n",
    "    f.write(\"\\nDETAILED RESULTS BY TOPIC\\n\")\n",
    "    f.write(\"========================\\n\\n\")\n",
    "    \n",
    "    for topic in coarse_topics:\n",
    "        f.write(f\"\\nTOPIC: {topic}\\n\")\n",
    "        f.write(\"=\" * (len(topic) + 7) + \"\\n\")\n",
    "        \n",
    "        # Get removed and retained indicators\n",
    "        removed = removed_indicators[topic]\n",
    "        retained = retained_indicators[topic]\n",
    "        \n",
    "        f.write(f\"Indicators removed ({len(removed)}):\\n\")\n",
    "        if removed:\n",
    "            for i, ind in enumerate(removed, 1):\n",
    "                code = indicator_to_code.get(ind, \"Unknown\")\n",
    "                f.write(f\"{i}. {ind} [{code}]\\n\")\n",
    "        else:\n",
    "            f.write(\"None\\n\")\n",
    "        \n",
    "        f.write(f\"\\nIndicators retained ({len(retained)}):\\n\")\n",
    "        if retained:\n",
    "            for i, ind in enumerate(retained, 1):\n",
    "                code = indicator_to_code.get(ind, \"Unknown\")\n",
    "                f.write(f\"{i}. {ind} [{code}]\\n\")\n",
    "        else:\n",
    "            f.write(\"None\\n\")\n",
    "        \n",
    "        f.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(f\"Saved detailed report to {report_file}\")\n",
    "\n",
    "# Create a visualization of the number of indicators removed vs. retained by topic\n",
    "summary_vis_df = summary_df.sort_values('Original_Indicator_Count', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "summary_vis_df['Indicators_Removed_Pct'] = summary_vis_df['Indicators_Removed'] / summary_vis_df['Original_Indicator_Count'] * 100\n",
    "\n",
    "# Bar chart of indicator counts\n",
    "ax = summary_vis_df.plot(\n",
    "    kind='bar', \n",
    "    x='Coarse_Topic', \n",
    "    y=['Indicators_Retained', 'Indicators_Removed'],\n",
    "    stacked=True, \n",
    "    color=['green', 'red'],\n",
    "    figsize=(14, 10)\n",
    ")\n",
    "plt.title('Indicators Retained vs. Removed by Coarse Topic (Top 15 by Indicator Count)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(['Retained', 'Removed'])\n",
    "plt.ylabel('Number of Indicators')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Percentage of indicators removed\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(summary_vis_df['Coarse_Topic'], summary_vis_df['Indicators_Removed_Pct'])\n",
    "plt.title('Percentage of Indicators Removed by Coarse Topic')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "\n",
    "summary_vis_file = output_dir / \"indicator_removal_summary.png\"\n",
    "plt.savefig(summary_vis_file, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved indicator removal summary visualization to {summary_vis_file}\")\n",
    "\n",
    "# Create a filtered dataset with only retained indicators\n",
    "print(\"Creating filtered dataset with only retained indicators...\")\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "for topic in coarse_topics:\n",
    "    topic_retained = retained_indicators[topic]\n",
    "    \n",
    "    if not topic_retained:\n",
    "        continue\n",
    "    \n",
    "    for indicator in topic_retained:\n",
    "        indicator_df = df[(df['Coarse_Topic'] == topic) & (df['Indicator Name'] == indicator)]\n",
    "        filtered_df = pd.concat([filtered_df, indicator_df])\n",
    "\n",
    "# Save filtered dataset\n",
    "filtered_file = output_dir / \"filtered_dataset_without_correlated_indicators.csv\"\n",
    "filtered_df.to_csv(filtered_file, index=False)\n",
    "print(f\"Saved filtered dataset to {filtered_file}\")\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
