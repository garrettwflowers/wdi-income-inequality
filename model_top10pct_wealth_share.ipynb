{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "416804b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Scipy stats for parameter distributions\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Disable file validation warning\n",
    "os.environ['PYDEVD_DISABLE_FILE_VALIDATION'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d9e54",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Define all path variables here for easy modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15210abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded. Using seed: 20250406\n"
     ]
    }
   ],
   "source": [
    "FILE_SUFFIX = 'top10pct_wealth_share'\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 20250406\n",
    "\n",
    "# Input paths\n",
    "INPUT_DIR = 'input'\n",
    "IMPUTED_DIR = f'{INPUT_DIR}/imputed'\n",
    "REFERENCE_DIR = 'reference'\n",
    "\n",
    "# Data files\n",
    "DATA_FILE = f'{IMPUTED_DIR}/df_wide_knn_imputed.csv'\n",
    "INDICATOR_LOOKUP_FILE = f'{REFERENCE_DIR}/indicator_lookup.csv'\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = 'output'\n",
    "MODELS_DIR = f'{OUTPUT_DIR}/models'\n",
    "PREDICTIONS_DIR = f'{OUTPUT_DIR}/predictions'\n",
    "FEATURE_IMPORTANCE_DIR = f'{OUTPUT_DIR}/feature_importance'\n",
    "\n",
    "# Output files\n",
    "# - Base model outputs\n",
    "MODEL_FILE = f'{MODELS_DIR}/xgb_model_{FILE_SUFFIX}.pkl'\n",
    "PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_predictions_{FILE_SUFFIX}.csv'\n",
    "FEATURE_IMPORTANCES_FILE = f'{FEATURE_IMPORTANCE_DIR}/feature_importances_{FILE_SUFFIX}.csv'\n",
    "\n",
    "# - Best model outputs\n",
    "BEST_MODEL_FILE = f'{MODELS_DIR}/xgb_best_model_{FILE_SUFFIX}.pkl'\n",
    "BEST_PREDICTIONS_FILE = f'{PREDICTIONS_DIR}/xgb_best_predictions_{FILE_SUFFIX}.csv'\n",
    "BEST_FEATURE_IMPORTANCES_FILE = f'{MODELS_DIR}/feature_importances_best_{FILE_SUFFIX}.csv'\n",
    "BEST_PARAMS_FILE = f'{MODELS_DIR}/best_model_params_{FILE_SUFFIX}.json'\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(PREDICTIONS_DIR, exist_ok=True)\n",
    "os.makedirs(FEATURE_IMPORTANCE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded. Using seed: {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5196303",
   "metadata": {},
   "source": [
    "# Select Data for Train/Test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67bad113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 20250406\n",
      "\n",
      "input/imputed/df_wide_knn_imputed.csv loaded.\n",
      "\n",
      "Full Data Shape: 16,960 x 1,485\n",
      "Full Data Elements: 25,185,600\n",
      "Target Shape: 16,960 x 2\n",
      "\n",
      "Data Shape (drop na on wealth indc): 2,110 x 1,485\n",
      "Data Elements (drop na on wealth indc): 3,133,350\n",
      "Target Shape (drop na on wealth indc): 2,110\n",
      "\n",
      "GINI Data Shape (drop na on GINI): 2,111 x 1,485\n",
      "GINI Data Elements (drop na on GINI): 3,134,835\n",
      "GINI Target Shape (drop na on GINI): 2,111 x 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"SEED: {SEED}\")\n",
    "\n",
    "data = pd.read_csv(DATA_FILE)\n",
    "print(f\"\\n{DATA_FILE} loaded.\")\n",
    "\n",
    "# Define target indicators for top and bottom 10% wealth share\n",
    "target_top = \"SI.DST.10TH.10\"    # Top 10% wealth share\n",
    "target_bottom = \"SI.DST.FRST.10\" # Bottom 10% wealth share\n",
    "target_gini = \"SI.POV.GINI\"      # Gini Index\n",
    "\n",
    "# Exclude identifier columns and target columns from features\n",
    "exclude_columns = [\"Country Name\", \"Country Code\", \"Year\", target_top, target_bottom, target_gini]\n",
    "wealth_share_columns = [col for col in data.columns if col.startswith(\"SI.DST\")]\n",
    "exclude_columns += wealth_share_columns\n",
    "feature_columns = [col for col in data.columns if col not in exclude_columns]\n",
    "\n",
    "# evaluate data completeness based on targets\n",
    "X_full = data[feature_columns].copy()\n",
    "y_full = data[[target_top, target_bottom]].copy()\n",
    "\n",
    "print(f\"\\nFull Data Shape: {X_full.shape[0]:,} x {X_full.shape[1]:,}\")\n",
    "print(f\"Full Data Elements: {X_full.size:,}\")\n",
    "print(f\"Target Shape: {y_full.shape[0]:,} x {y_full.shape[1]:,}\")\n",
    "\n",
    "X_wealth = data.dropna(subset=[target_top, target_bottom])[feature_columns].copy()\n",
    "y_wealth = data.dropna(subset=[target_top, target_bottom])[target_top].copy()\n",
    "\n",
    "print(f\"\\nData Shape (drop na on wealth indc): {X_wealth.shape[0]:,} x {X_wealth.shape[1]:,}\")\n",
    "print(f\"Data Elements (drop na on wealth indc): {X_wealth.size:,}\")\n",
    "print(f\"Target Shape (drop na on wealth indc): {y_wealth.shape[0]:,}\")\n",
    "\n",
    "X_gini = data.dropna(subset=[target_gini])[feature_columns].copy()\n",
    "y_gini = data.dropna(subset=[target_gini])[[target_gini]].copy()\n",
    "\n",
    "print(f\"\\nGINI Data Shape (drop na on GINI): {X_gini.shape[0]:,} x {X_gini.shape[1]:,}\")\n",
    "print(f\"GINI Data Elements (drop na on GINI): {X_gini.size:,}\")\n",
    "print(f\"GINI Target Shape (drop na on GINI): {y_gini.shape[0]:,} x {y_gini.shape[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "183e8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Shape: 2,110 x 1,485\n",
      "Data elements: 3,133,350\n"
     ]
    }
   ],
   "source": [
    "# data selection\n",
    "X = X_wealth.values\n",
    "y = y_wealth.values\n",
    "\n",
    "print(f\"\\nData Shape: {X.shape[0]:,} x {X.shape[1]:,}\")\n",
    "print(f\"Data elements: {X.size:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad58538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Shape: 1,477 x 1,485\n",
      "Train elements: 2,193,345\n",
      "Train target elements: 1,477\n",
      "\n",
      "Validation Shape: 316 x 1,485\n",
      "Validation elements: 469,260\n",
      "Validation target elements: 316\n",
      "\n",
      "Test Shape: 317 x 1,485\n",
      "Test elements: 470,745\n",
      "Test target elements: 317\n",
      "\n",
      "Pct split: 70.00% train, 14.98% val, 15.02% test\n"
     ]
    }
   ],
   "source": [
    "# train test validation split\n",
    "# Simple approach: random split treating each observation independently\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=SEED\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain Shape: {X_train.shape[0]:,} x {X_train.shape[1]:,}\")\n",
    "print(f\"Train elements: {X_train.size:,}\")\n",
    "print(f\"Train target elements: {y_train.size:,}\")\n",
    "print(f\"\\nValidation Shape: {X_val.shape[0]:,} x {X_val.shape[1]:,}\")\n",
    "print(f\"Validation elements: {X_val.size:,}\")\n",
    "print(f\"Validation target elements: {y_val.size:,}\")\n",
    "print(f\"\\nTest Shape: {X_test.shape[0]:,} x {X_test.shape[1]:,}\")\n",
    "print(f\"Test elements: {X_test.size:,}\")\n",
    "print(f\"Test target elements: {y_test.size:,}\")\n",
    "print(f\"\\nPct split: {X_train.shape[0] / X.shape[0]:.2%} train, {X_val.shape[0] / X.shape[0]:.2%} val, {X_test.shape[0] / X.shape[0]:.2%} test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6021b2",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1513a5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train MSE: 3.1557, Train R2: 0.9292\n",
      "Validation MSE: 5.2340, Validation R2: 0.8886\n",
      "Test MSE: 7.9941, Test R2: 0.8470\n",
      "\n",
      "Model saved to output/models/xgb_model_top10pct_wealth_share.pkl\n",
      "\n",
      "Predictions saved to output/predictions/xgb_predictions_top10pct_wealth_share.csv\n",
      "\n",
      "Feature importances saved to output/feature_importance/feature_importances_top10pct_wealth_share.csv\n",
      "\n",
      "Top 10 feature importances:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3073a024-52cc-4e68-85e4-9442e1b61ae4",
       "rows": [
        [
         "0",
         "TM.TAX.MRCH.BR.ZS",
         "Bound rate, simple mean, all products (%)",
         "0.13998197"
        ],
        [
         "1",
         "SH.STA.ODFC.UR.ZS",
         "People practicing open defecation, urban (% of urban population)",
         "0.08845479"
        ],
        [
         "2",
         "SH.MED.SAOP.P5",
         "Specialist surgical workforce (per 100,000 population)",
         "0.058231723"
        ],
        [
         "3",
         "SP.ADO.TFRT",
         "Adolescent fertility rate (births per 1,000 women ages 15-19)",
         "0.05669631"
        ],
        [
         "4",
         "per_si_allsi.cov_q1_tot",
         "Coverage of social insurance programs in poorest quintile (% of population)",
         "0.04502844"
        ],
        [
         "5",
         "TM.TAX.MANF.BR.ZS",
         "Bound rate, simple mean, manufactured products (%)",
         "0.04502657"
        ],
        [
         "6",
         "SH.DTH.COMM.ZS",
         "Cause of death, by communicable diseases and maternal, prenatal and nutrition conditions (% of total)",
         "0.01885094"
        ],
        [
         "7",
         "EG.ELC.ACCS.RU.ZS",
         "Access to electricity, rural (% of rural population)",
         "0.016455594"
        ],
        [
         "8",
         "VC.IHR.PSRC.P5",
         "Intentional homicides (per 100,000 people)",
         "0.014219261"
        ],
        [
         "9",
         "SH.DTH.INJR.ZS",
         "Cause of death, by injury (% of total)",
         "0.012786346"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TM.TAX.MRCH.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, all products (%)</td>\n",
       "      <td>0.139982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SH.STA.ODFC.UR.ZS</td>\n",
       "      <td>People practicing open defecation, urban (% of...</td>\n",
       "      <td>0.088455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SH.MED.SAOP.P5</td>\n",
       "      <td>Specialist surgical workforce (per 100,000 pop...</td>\n",
       "      <td>0.058232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>0.056696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>per_si_allsi.cov_q1_tot</td>\n",
       "      <td>Coverage of social insurance programs in poore...</td>\n",
       "      <td>0.045028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TM.TAX.MANF.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, manufactured products...</td>\n",
       "      <td>0.045027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SH.DTH.COMM.ZS</td>\n",
       "      <td>Cause of death, by communicable diseases and m...</td>\n",
       "      <td>0.018851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EG.ELC.ACCS.RU.ZS</td>\n",
       "      <td>Access to electricity, rural (% of rural popul...</td>\n",
       "      <td>0.016456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VC.IHR.PSRC.P5</td>\n",
       "      <td>Intentional homicides (per 100,000 people)</td>\n",
       "      <td>0.014219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SH.DTH.INJR.ZS</td>\n",
       "      <td>Cause of death, by injury (% of total)</td>\n",
       "      <td>0.012786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indicator Code                                     Indicator Name  \\\n",
       "0        TM.TAX.MRCH.BR.ZS          Bound rate, simple mean, all products (%)   \n",
       "1        SH.STA.ODFC.UR.ZS  People practicing open defecation, urban (% of...   \n",
       "2           SH.MED.SAOP.P5  Specialist surgical workforce (per 100,000 pop...   \n",
       "3              SP.ADO.TFRT  Adolescent fertility rate (births per 1,000 wo...   \n",
       "4  per_si_allsi.cov_q1_tot  Coverage of social insurance programs in poore...   \n",
       "5        TM.TAX.MANF.BR.ZS  Bound rate, simple mean, manufactured products...   \n",
       "6           SH.DTH.COMM.ZS  Cause of death, by communicable diseases and m...   \n",
       "7        EG.ELC.ACCS.RU.ZS  Access to electricity, rural (% of rural popul...   \n",
       "8           VC.IHR.PSRC.P5         Intentional homicides (per 100,000 people)   \n",
       "9           SH.DTH.INJR.ZS             Cause of death, by injury (% of total)   \n",
       "\n",
       "   Importance  \n",
       "0    0.139982  \n",
       "1    0.088455  \n",
       "2    0.058232  \n",
       "3    0.056696  \n",
       "4    0.045028  \n",
       "5    0.045027  \n",
       "6    0.018851  \n",
       "7    0.016456  \n",
       "8    0.014219  \n",
       "9    0.012786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = xgb.XGBRegressor(\n",
    "    # Basic parameters\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.05,  # Lower learning rate for better generalization\n",
    "    \n",
    "    # Tree structure regularization\n",
    "    max_depth=3,  # Lower max_depth to prevent complex trees\n",
    "    min_child_weight=5,  # Higher values prevent overfitting on rare feature combinations\n",
    "    gamma=1,  # Minimum loss reduction required for further partition\n",
    "    \n",
    "    # Sampling regularization\n",
    "    subsample=0.8,  # Train on 80% of data points each iteration\n",
    "    colsample_bytree=0.7,  # Train each tree on 70% of features\n",
    "    colsample_bylevel=0.7,  # Sample features at each level\n",
    "    \n",
    "    # L1/L2 regularization\n",
    "    reg_alpha=1.0,  # L1 regularization on weights\n",
    "    reg_lambda=1.0,  # L2 regularization on weights\n",
    "    \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_val = pipeline.predict(X_val)\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "val_mse = mean_squared_error(y_val, y_pred_val)\n",
    "val_r2 = r2_score(y_val, y_pred_val)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "print(f\"\\nTrain MSE: {train_mse:.4f}, Train R2: {train_r2:.4f}\")\n",
    "print(f\"Validation MSE: {val_mse:.4f}, Validation R2: {val_r2:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}, Test R2: {test_r2:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(pipeline, MODEL_FILE)\n",
    "print(f\"\\nModel saved to {MODEL_FILE}\")\n",
    "\n",
    "# Save the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test\n",
    "})\n",
    "predictions_df.to_csv(PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nPredictions saved to {PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the feature importances\n",
    "importances = pipeline.named_steps['model'].feature_importances_\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_df.to_csv(FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nFeature importances saved to {FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances:\")\n",
    "feature_lookup = pd.read_csv(INDICATOR_LOOKUP_FILE)\n",
    "feature_importances_df = feature_importances_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bf6d5",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a035450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "Best parameters: {'model__colsample_bylevel': 0.7407960993273509, 'model__colsample_bytree': 0.9508410181190827, 'model__gamma': 1.3047560001770928, 'model__learning_rate': 0.05116466295321231, 'model__max_depth': 5, 'model__min_child_weight': 2, 'model__n_estimators': 170, 'model__reg_alpha': 0.7575176304276007, 'model__reg_lambda': 3.4392701633892786, 'model__subsample': 0.9233807090140386}\n",
      "Best cross-validation RMSE: 2.2326\n",
      "\n",
      "Train RMSE (best model): 0.5224, Train R2 (best model): 0.9939\n",
      "Validation RMSE (best model): 2.0052, Validation R2 (best model): 0.9144\n",
      "Test RMSE (best model): 2.4901, Test R2 (best model): 0.8814\n",
      "\n",
      "Best model saved to output/models/xgb_best_model_top10pct_wealth_share.pkl\n",
      "\n",
      "Best model predictions saved to output/predictions/xgb_best_predictions_top10pct_wealth_share.csv\n",
      "\n",
      "Best model feature importances saved to output/models/feature_importances_best_top10pct_wealth_share.csv\n",
      "\n",
      "Top 10 feature importances (best model):\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Indicator Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Indicator Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4aeff4d7-9d74-4aab-a4d4-4090cbe8d5ed",
       "rows": [
        [
         "0",
         "TM.TAX.MANF.BR.ZS",
         "Bound rate, simple mean, manufactured products (%)",
         "0.14093779"
        ],
        [
         "1",
         "SP.ADO.TFRT",
         "Adolescent fertility rate (births per 1,000 women ages 15-19)",
         "0.07960517"
        ],
        [
         "2",
         "TM.TAX.MRCH.BR.ZS",
         "Bound rate, simple mean, all products (%)",
         "0.07493752"
        ],
        [
         "3",
         "VC.IHR.PSRC.P5",
         "Intentional homicides (per 100,000 people)",
         "0.025034728"
        ],
        [
         "4",
         "per_si_allsi.cov_q1_tot",
         "Coverage of social insurance programs in poorest quintile (% of population)",
         "0.022160226"
        ],
        [
         "5",
         "TM.VAL.MRCH.R3.ZS",
         "Merchandise imports from low- and middle-income economies in Latin America & the Caribbean (% of total merchandise imports)",
         "0.017294083"
        ],
        [
         "6",
         "IC.FRM.RSDV.ZS",
         "Firms that spend on R&D (% of firms)",
         "0.015861861"
        ],
        [
         "7",
         "SI.POV.SOPO",
         "Poverty headcount ratio at societal poverty line (% of population)",
         "0.014742274"
        ],
        [
         "8",
         "IC.CRD.PRVT.ZS",
         "Private credit bureau coverage (% of adults)",
         "0.013405355"
        ],
        [
         "9",
         "SH.DYN.AIDS.ZS",
         "Prevalence of HIV, total (% of population ages 15-49)",
         "0.012590114"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TM.TAX.MANF.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, manufactured products...</td>\n",
       "      <td>0.140938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SP.ADO.TFRT</td>\n",
       "      <td>Adolescent fertility rate (births per 1,000 wo...</td>\n",
       "      <td>0.079605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TM.TAX.MRCH.BR.ZS</td>\n",
       "      <td>Bound rate, simple mean, all products (%)</td>\n",
       "      <td>0.074938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VC.IHR.PSRC.P5</td>\n",
       "      <td>Intentional homicides (per 100,000 people)</td>\n",
       "      <td>0.025035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>per_si_allsi.cov_q1_tot</td>\n",
       "      <td>Coverage of social insurance programs in poore...</td>\n",
       "      <td>0.022160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TM.VAL.MRCH.R3.ZS</td>\n",
       "      <td>Merchandise imports from low- and middle-incom...</td>\n",
       "      <td>0.017294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IC.FRM.RSDV.ZS</td>\n",
       "      <td>Firms that spend on R&amp;D (% of firms)</td>\n",
       "      <td>0.015862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SI.POV.SOPO</td>\n",
       "      <td>Poverty headcount ratio at societal poverty li...</td>\n",
       "      <td>0.014742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IC.CRD.PRVT.ZS</td>\n",
       "      <td>Private credit bureau coverage (% of adults)</td>\n",
       "      <td>0.013405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SH.DYN.AIDS.ZS</td>\n",
       "      <td>Prevalence of HIV, total (% of population ages...</td>\n",
       "      <td>0.012590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Indicator Code                                     Indicator Name  \\\n",
       "0        TM.TAX.MANF.BR.ZS  Bound rate, simple mean, manufactured products...   \n",
       "1              SP.ADO.TFRT  Adolescent fertility rate (births per 1,000 wo...   \n",
       "2        TM.TAX.MRCH.BR.ZS          Bound rate, simple mean, all products (%)   \n",
       "3           VC.IHR.PSRC.P5         Intentional homicides (per 100,000 people)   \n",
       "4  per_si_allsi.cov_q1_tot  Coverage of social insurance programs in poore...   \n",
       "5        TM.VAL.MRCH.R3.ZS  Merchandise imports from low- and middle-incom...   \n",
       "6           IC.FRM.RSDV.ZS               Firms that spend on R&D (% of firms)   \n",
       "7              SI.POV.SOPO  Poverty headcount ratio at societal poverty li...   \n",
       "8           IC.CRD.PRVT.ZS       Private credit bureau coverage (% of adults)   \n",
       "9           SH.DYN.AIDS.ZS  Prevalence of HIV, total (% of population ages...   \n",
       "\n",
       "   Importance  \n",
       "0    0.140938  \n",
       "1    0.079605  \n",
       "2    0.074938  \n",
       "3    0.025035  \n",
       "4    0.022160  \n",
       "5    0.017294  \n",
       "6    0.015862  \n",
       "7    0.014742  \n",
       "8    0.013405  \n",
       "9    0.012590  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model parameters saved to output/models/best_model_params_top10pct_wealth_share.json\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'model__n_estimators': randint(50, 200),\n",
    "    'model__learning_rate': uniform(0.01, 0.1),  \n",
    "    'model__max_depth': randint(2, 6),           \n",
    "    'model__min_child_weight': randint(1, 6),    \n",
    "    'model__gamma': uniform(0, 2),               \n",
    "    'model__subsample': uniform(0.7, 0.3),       \n",
    "    'model__colsample_bytree': uniform(0.7, 0.3),\n",
    "    'model__colsample_bylevel': uniform(0.7, 0.3),\n",
    "    'model__reg_alpha': uniform(0, 3),           \n",
    "    'model__reg_lambda': uniform(0.5, 3)         \n",
    "}\n",
    "\n",
    "# Create a pipeline with scaling and the model\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', xgb.XGBRegressor(objective='reg:squarederror', random_state=SEED))\n",
    "])\n",
    "\n",
    "# Define the scoring function\n",
    "rmse_scorer = make_scorer(lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred)), \n",
    "                          greater_is_better=False)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25,  # Number of parameter combinations to try\n",
    "    cv=5,       # 5-fold cross-validation\n",
    "    scoring=rmse_scorer,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "best_model = random_search.best_estimator_\n",
    "print(f\"\\nBest parameters: {best_params}\")\n",
    "print(f\"Best cross-validation RMSE: {-best_score:.4f}\")\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_train_best = best_model.predict(X_train)\n",
    "y_pred_val_best = best_model.predict(X_val)\n",
    "y_pred_test_best = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "train_mse_best = mean_squared_error(y_train, y_pred_train_best)\n",
    "train_r2_best = r2_score(y_train, y_pred_train_best)\n",
    "val_mse_best = mean_squared_error(y_val, y_pred_val_best)\n",
    "val_r2_best = r2_score(y_val, y_pred_val_best)\n",
    "test_mse_best = mean_squared_error(y_test, y_pred_test_best)\n",
    "test_r2_best = r2_score(y_test, y_pred_test_best)\n",
    "\n",
    "# Add RMSE calculation\n",
    "train_rmse_best = np.sqrt(train_mse_best)\n",
    "val_rmse_best = np.sqrt(val_mse_best)\n",
    "test_rmse_best = np.sqrt(test_mse_best)\n",
    "\n",
    "print(f\"\\nTrain RMSE (best model): {train_rmse_best:.4f}, Train R2 (best model): {train_r2_best:.4f}\")\n",
    "print(f\"Validation RMSE (best model): {val_rmse_best:.4f}, Validation R2 (best model): {val_r2_best:.4f}\")\n",
    "print(f\"Test RMSE (best model): {test_rmse_best:.4f}, Test R2 (best model): {test_r2_best:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, BEST_MODEL_FILE)\n",
    "print(f\"\\nBest model saved to {BEST_MODEL_FILE}\")\n",
    "\n",
    "# Save the best model predictions\n",
    "predictions_best_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test_best\n",
    "})\n",
    "predictions_best_df.to_csv(BEST_PREDICTIONS_FILE, index=False)\n",
    "print(f\"\\nBest model predictions saved to {BEST_PREDICTIONS_FILE}\")\n",
    "\n",
    "# Save the best model feature importances\n",
    "importances_best = best_model.named_steps['model'].feature_importances_\n",
    "feature_importances_best_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': importances_best\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "feature_importances_best_df.to_csv(BEST_FEATURE_IMPORTANCES_FILE, index=False)\n",
    "print(f\"\\nBest model feature importances saved to {BEST_FEATURE_IMPORTANCES_FILE}\")\n",
    "\n",
    "print(\"\\nTop 10 feature importances (best model):\")\n",
    "feature_importances_best_df = feature_importances_best_df.merge(feature_lookup[['Indicator Code','Indicator Name']], how='left', left_on='Feature', right_on='Indicator Code')\n",
    "display(feature_importances_best_df[['Indicator Code', 'Indicator Name', 'Importance']].head(10))\n",
    "\n",
    "# Save the best model parameters\n",
    "with open(BEST_PARAMS_FILE, 'w') as f:\n",
    "    json.dump(best_params, f)\n",
    "print(f\"\\nBest model parameters saved to {BEST_PARAMS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
